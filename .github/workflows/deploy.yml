name: Deploy SecureAuditAI Agent

permissions:
  id-token: write
  contents: read

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - prod
          - cleanup

env:
  AWS_REGION: us-west-2
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # Validate Infrastructure
  validate:
    name: Validate Infrastructure
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/personal-github-oidc-role
          aws-region: ${{ env.AWS_REGION }}

      - name: Validate CloudFormation template
        run: aws cloudformation validate-template --template-body file://cloudformation/template.yaml

      - name: Validate Lambda packages exist
        run: |
          [ -f "lambda/trigger_scan.py" ] || (echo "trigger_scan.py missing" && exit 1)
          [ -f "lambda/api_audit_runs.py" ] || (echo "api_audit_runs.py missing" && exit 1)
          [ -f "lambda/api_findings.py" ] || (echo "api_findings.py missing" && exit 1)

  # Deploy to Environment
  deploy:
    name: Deploy to ${{ github.event.inputs.environment }}
    runs-on: ubuntu-latest
    needs: validate
    if: github.event.inputs.environment != 'cleanup'
    environment: ${{ github.event.inputs.environment }}
    concurrency:
      group: deploy-${{ github.event.inputs.environment }}-${{ github.ref }}
      cancel-in-progress: false
    timeout-minutes: 45
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/personal-github-oidc-role
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup AWS CLI
        run: |
          # AWS CLI is already configured via OIDC, no additional setup needed
          aws --version

      - name: Setup Node.js with caching
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Cache CloudFormation validation
        uses: actions/cache@v3
        id: cf-validate-cache
        with:
          path: .cf-validation
          key: cf-validation-${{ hashFiles('cloudformation/template.yaml') }}

      - name: Validate CloudFormation template (cached)
        if: steps.cf-validate-cache.outputs.cache-hit != 'true'
        run: |
          aws cloudformation validate-template --template-body file://cloudformation/template.yaml
          touch .cf-validation

      - name: Generate deterministic Cognito domain prefix
        id: generate-domain
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          SUFFIX=$(aws sts get-caller-identity --query Account --output text | tail -c 9 | tr -cd 'a-z0-9')
          COGNITO_PREFIX="secureauditai-${ENVIRONMENT}-${SUFFIX}"

          if [[ ! "$COGNITO_PREFIX" =~ ^[a-z0-9]([a-z0-9-]*[a-z0-9])?$ ]] || [[ ${#COGNITO_PREFIX} -lt 1 ]] || [[ ${#COGNITO_PREFIX} -gt 63 ]]; then
            echo "Invalid domain format: $COGNITO_PREFIX"
            exit 1
          fi

          echo "COGNITO_DOMAIN=${COGNITO_PREFIX}" >> $GITHUB_OUTPUT

      - name: Setup S3 bucket for deployment artifacts
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          BUCKET_NAME="secureauditai-deployment-us-west-2-${ENVIRONMENT}"
          echo "DEPLOYMENT_BUCKET=${BUCKET_NAME}" >> $GITHUB_ENV

          # Check if bucket exists, create if not
          if ! aws s3 ls s3://${BUCKET_NAME} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            aws s3 mb s3://${BUCKET_NAME} --region ${{ env.AWS_REGION }} || (echo "Failed to create deployment bucket" && exit 1)
          fi

      - name: Package CloudFormation template
        run: |
          aws cloudformation package \
            --template-file cloudformation/template.yaml \
            --s3-bucket ${{ env.DEPLOYMENT_BUCKET }} \
            --output-template-file packaged-template.yaml \
            --region ${{ env.AWS_REGION }}

      - name: Cache Lambda packages
        uses: actions/cache@v3
        id: lambda-cache
        with:
          path: |
            lambda/*.zip
          key: lambda-packages-${{ hashFiles('lambda/*.py') }}-${{ github.event.inputs.environment }}

      - name: Package Lambda functions (cached)
        if: steps.lambda-cache.outputs.cache-hit != 'true'
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          cd lambda

          # Package Lambda functions with environment suffix for prod
          if [ "$ENVIRONMENT" = "prod" ]; then
            zip -r trigger_scan-${ENVIRONMENT}.zip trigger_scan.py
            zip -r api_audit_runs-${ENVIRONMENT}.zip api_audit_runs.py
            zip -r api_findings-${ENVIRONMENT}.zip api_findings.py
          else
            zip -r trigger_scan.zip trigger_scan.py
            zip -r api_audit_runs.zip api_audit_runs.py
            zip -r api_findings.zip api_findings.py
          fi

      - name: Upload Lambda packages to S3
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          cd lambda

          if [ "$ENVIRONMENT" = "prod" ]; then
            aws s3 cp trigger_scan-${ENVIRONMENT}.zip s3://${{ env.DEPLOYMENT_BUCKET }}/lambda/trigger_scan-${ENVIRONMENT}.zip --region ${{ env.AWS_REGION }}
            aws s3 cp api_audit_runs-${ENVIRONMENT}.zip s3://${{ env.DEPLOYMENT_BUCKET }}/lambda/api_audit_runs-${ENVIRONMENT}.zip --region ${{ env.AWS_REGION }}
            aws s3 cp api_findings-${ENVIRONMENT}.zip s3://${{ env.DEPLOYMENT_BUCKET }}/lambda/api_findings-${ENVIRONMENT}.zip --region ${{ env.AWS_REGION }}
          else
            aws s3 cp trigger_scan.zip s3://${{ env.DEPLOYMENT_BUCKET }}/lambda/trigger_scan.zip --region ${{ env.AWS_REGION }}
            aws s3 cp api_audit_runs.zip s3://${{ env.DEPLOYMENT_BUCKET }}/lambda/api_audit_runs.zip --region ${{ env.AWS_REGION }}
            aws s3 cp api_findings.zip s3://${{ env.DEPLOYMENT_BUCKET }}/lambda/api_findings.zip --region ${{ env.AWS_REGION }}
          fi

      - name: Deploy CloudFormation stack
        id: deploy-stack
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          STACK_NAME="secureauditai-agent-${ENVIRONMENT}"

          if aws cloudformation describe-stacks --stack-name "$STACK_NAME" --region ${{ env.AWS_REGION }} &> /dev/null; then
            # Enable termination protection before update
            aws cloudformation update-termination-protection \
              --stack-name "$STACK_NAME" \
              --enable-termination-protection \
              --region ${{ env.AWS_REGION }}

            echo "Updating CloudFormation stack: $STACK_NAME"
            if aws cloudformation update-stack \
              --stack-name "$STACK_NAME" \
              --template-body file://packaged-template.yaml \
              --parameters \
                ParameterKey=Environment,ParameterValue="$ENVIRONMENT" \
                ParameterKey=BedrockModelId,ParameterValue="${{ secrets.BEDROCK_MODEL_ID || 'amazon.titan-text-premier-v1:0' }}" \
                ParameterKey=LambdaCodeBucketName,ParameterValue="${{ env.DEPLOYMENT_BUCKET }}" \
              --capabilities CAPABILITY_NAMED_IAM \
              --rollback-configuration RollbackTriggers=[],MonitoringTimeInMinutes=5 \
              --region ${{ env.AWS_REGION }}; then

              echo "Stack update initiated successfully"
              # Wait for stack update to complete
              aws cloudformation wait stack-update-complete \
                --stack-name "$STACK_NAME" \
                --region ${{ env.AWS_REGION }}
              echo "Stack update completed successfully"
            else
              echo "Stack update failed or no changes detected"
              # Check current stack status
              STACK_STATUS=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].StackStatus' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "UNKNOWN")
              if [[ "$STACK_STATUS" == *"FAILED"* ]] || [[ "$STACK_STATUS" == *"ROLLBACK"* ]]; then
                echo "Stack is in failed state: $STACK_STATUS"
                echo "Please check CloudFormation console for details"
                exit 1
              else
                echo "Stack status: $STACK_STATUS"
              fi
            fi
          else
            aws cloudformation create-stack \
              --stack-name "$STACK_NAME" \
              --template-body file://packaged-template.yaml \
              --parameters \
                ParameterKey=Environment,ParameterValue="$ENVIRONMENT" \
                ParameterKey=BedrockModelId,ParameterValue="${{ secrets.BEDROCK_MODEL_ID || 'amazon.titan-text-premier-v1:0' }}" \
                ParameterKey=LambdaCodeBucketName,ParameterValue="${{ env.DEPLOYMENT_BUCKET }}" \
              --capabilities CAPABILITY_NAMED_IAM \
              --enable-termination-protection \
              --rollback-configuration RollbackTriggers=[],MonitoringTimeInMinutes=5 \
              --region ${{ env.AWS_REGION }}

            aws cloudformation wait stack-create-complete \
              --stack-name "$STACK_NAME" \
              --region ${{ env.AWS_REGION }}
          fi

      - name: Get CloudFormation outputs
        id: cf-outputs
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          STACK_NAME="secureauditai-agent-${ENVIRONMENT}"

          USER_POOL_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].Outputs[?OutputKey==`UserPoolId`].OutputValue' --output text --region ${{ env.AWS_REGION }})
          USER_POOL_CLIENT_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].Outputs[?OutputKey==`UserPoolClientId`].OutputValue' --output text --region ${{ env.AWS_REGION }})
          API_GATEWAY_URL=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].Outputs[?OutputKey==`ApiGatewayUrl`].OutputValue' --output text --region ${{ env.AWS_REGION }})
          AMPLIFY_APP_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].Outputs[?OutputKey==`AmplifyAppId`].OutputValue' --output text --region ${{ env.AWS_REGION }})
          AMPLIFY_APP_URL=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].Outputs[?OutputKey==`AmplifyAppUrl`].OutputValue' --output text --region ${{ env.AWS_REGION }})
          FRONTEND_BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue' --output text --region ${{ env.AWS_REGION }})

          echo "USER_POOL_ID=${USER_POOL_ID}" >> $GITHUB_OUTPUT
          echo "USER_POOL_CLIENT_ID=${USER_POOL_CLIENT_ID}" >> $GITHUB_OUTPUT
          echo "API_GATEWAY_URL=${API_GATEWAY_URL}" >> $GITHUB_OUTPUT
          echo "AMPLIFY_APP_ID=${AMPLIFY_APP_ID}" >> $GITHUB_OUTPUT
          echo "AMPLIFY_APP_URL=${AMPLIFY_APP_URL}" >> $GITHUB_OUTPUT
          echo "FRONTEND_BUCKET_NAME=${FRONTEND_BUCKET_NAME}" >> $GITHUB_OUTPUT

      - name: Create Cognito domain
        run: |
          COGNITO_DOMAIN="${{ steps.generate-domain.outputs.COGNITO_DOMAIN }}"
          USER_POOL_ID="${{ steps.cf-outputs.outputs.USER_POOL_ID }}"

          if ! aws cognito-idp describe-user-pool-domain --domain "$COGNITO_DOMAIN" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            aws cognito-idp create-user-pool-domain \
              --domain "$COGNITO_DOMAIN" \
              --user-pool-id "$USER_POOL_ID" \
              --region ${{ env.AWS_REGION }}
          fi

      - name: Cache frontend dependencies
        uses: actions/cache@v3
        id: frontend-deps-cache
        with:
          path: |
            frontend/node_modules
            ~/.npm
          key: frontend-deps-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            frontend-deps-

      - name: Install frontend dependencies
        run: |
          cd frontend
          npm install
        env:
          CI: false

      - name: Build frontend application
        id: build-frontend
        run: |
          cd frontend

          # Configure frontend with CloudFormation outputs
          node ../scripts/configure-frontend.js "${{ steps.cf-outputs.outputs.USER_POOL_ID }}" "${{ steps.cf-outputs.outputs.USER_POOL_CLIENT_ID }}" "${{ steps.cf-outputs.outputs.API_GATEWAY_URL }}" "${{ env.AWS_REGION }}" "${{ github.event.inputs.environment }}"

          # Build frontend for production
          npm run build:prod

      - name: Deploy React frontend to Amplify
        id: deploy-amplify
        run: |
          cd frontend

          # Create a deployment package
          cd build
          zip -r ../amplify-deployment.zip .
          cd ..

          ENVIRONMENT="${{ github.event.inputs.environment }}"
          AMPLIFY_APP_ID="${{ steps.cf-outputs.outputs.AMPLIFY_APP_ID }}"

          # Create deployment
          DEPLOYMENT_OUTPUT=$(aws amplify create-deployment \
            --app-id "$AMPLIFY_APP_ID" \
            --branch-name "$ENVIRONMENT" \
            --region ${{ env.AWS_REGION }} \
            --output json)

          UPLOAD_URL=$(echo "$DEPLOYMENT_OUTPUT" | jq -r '.zipUploadUrl')
          JOB_ID=$(echo "$DEPLOYMENT_OUTPUT" | jq -r '.jobId')

          # Upload the zip file to the pre-signed URL with retry
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if curl -X PUT "$UPLOAD_URL" \
              -H "Content-Type: application/zip" \
              --max-time 300 \
              --data-binary @amplify-deployment.zip; then
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                sleep 10
              else
                echo "Failed to upload frontend package after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done

          # Start the deployment
          aws amplify start-deployment \
            --app-id "$AMPLIFY_APP_ID" \
            --branch-name "$ENVIRONMENT" \
            --job-id "$JOB_ID" \
            --region ${{ env.AWS_REGION }} || (echo "Failed to start Amplify deployment" && exit 1)

          # Wait for deployment completion
          MAX_WAIT=900  # 15 minutes
          WAIT_TIME=0
          while [ $WAIT_TIME -lt $MAX_WAIT ]; do
            JOB_STATUS=$(aws amplify get-job --app-id "$AMPLIFY_APP_ID" --branch-name "$ENVIRONMENT" --job-id "$JOB_ID" --query 'job.summary.status' --output text --region ${{ env.AWS_REGION }})
            if [ "$JOB_STATUS" = "SUCCEED" ]; then
              break
            elif [ "$JOB_STATUS" = "FAILED" ] || [ "$JOB_STATUS" = "CANCELLED" ]; then
              echo "Amplify deployment failed with status: $JOB_STATUS"
              exit 1
            fi
            sleep 30
            WAIT_TIME=$((WAIT_TIME + 30))
          done

          if [ $WAIT_TIME -ge $MAX_WAIT ]; then
            echo "Amplify deployment timed out after 15 minutes"
            exit 1
          fi

          # Upload frontend build to S3 bucket for backup/static hosting
          aws s3 sync build/ s3://${{ steps.cf-outputs.outputs.FRONTEND_BUCKET_NAME }}/ --delete --region ${{ env.AWS_REGION }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Bedrock AgentCore Starter Toolkit
        run: |
          pip install bedrock-agentcore-starter-toolkit boto3

      - name: Setup AgentCore Memory and Gateway (Optional)
        id: setup-agentcore-resources
        continue-on-error: true
        run: |
          cd agent
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          STACK_NAME="secureauditai-agent"
          
          echo "⚠️  Skipping Memory and Gateway setup - not available in this region/account"
          echo "Agent will run without persistent memory features"
          
          # Set empty outputs
          echo "memory_id=" >> $GITHUB_OUTPUT
          echo "gateway_id=" >> $GITHUB_OUTPUT
          echo "gateway_endpoint=" >> $GITHUB_OUTPUT

      - name: Configure AgentCore Runtime
        id: configure-agentcore
        run: |
          cd agent
          ENVIRONMENT="${{ github.event.inputs.environment }}"

          # Configure the agent
          echo "🔧 Configuring AgentCore agent..."
          CONFIG_OUTPUT=$(agentcore configure \
            --entrypoint main.py \
            --name "secureauditai_agent_${ENVIRONMENT}" \
            --region ${{ env.AWS_REGION }} \
            --requirements-file requirements.txt \
            --non-interactive 2>&1)
          CONFIG_EXIT_CODE=$?
          echo "Configure exit code: $CONFIG_EXIT_CODE"
          echo "Configure output:"
          echo "$CONFIG_OUTPUT"

          if [ $CONFIG_EXIT_CODE -ne 0 ]; then
            echo "❌ AgentCore configure failed with exit code $CONFIG_EXIT_CODE"
            exit $CONFIG_EXIT_CODE
          fi

          # Verify configuration was created
          if [ ! -f ".bedrock_agentcore.yaml" ]; then
            echo "❌ Configuration file .bedrock_agentcore.yaml was not created"
            exit 1
          fi

          echo "✅ AgentCore configuration completed successfully"
          echo "agent_name=secureauditai_agent_${ENVIRONMENT}" >> $GITHUB_OUTPUT

      - name: Deploy AgentCore Runtime
        id: deploy-agentcore
        run: |
          cd agent
          ENVIRONMENT="${{ github.event.inputs.environment }}"

          # Install agent dependencies before launch
          echo "📦 Installing agent dependencies..."
          pip install -r requirements.txt

          # Verify agentcore is available
          echo "🔍 Checking agentcore availability..."
          if ! command -v agentcore &> /dev/null; then
            echo "❌ agentcore command not found"
            exit 1
          fi

          # Test that the agent code can be imported
          echo "🧪 Testing agent imports..."
          if ! python3 -c "import main; print('✅ Agent imports successful')" 2>&1; then
            echo "❌ Agent import failed"
            exit 1
          fi

          # Check if configuration exists
          if [ ! -f ".bedrock_agentcore.yaml" ]; then
            echo "❌ AgentCore configuration file .bedrock_agentcore.yaml not found"
            echo "Listing agent directory contents:"
            ls -la
            exit 1
          fi

          # Launch the AgentCore Runtime (without Memory/Gateway for now)
          # Set environment variables for launch
          export AWS_REGION=${{ env.AWS_REGION }}
          export AWS_DEFAULT_REGION=${{ env.AWS_REGION }}

          # Capture the output which should contain the runtime ARN
          echo "🚀 Starting AgentCore launch..."
          LAUNCH_OUTPUT=$(agentcore launch 2>&1)
          LAUNCH_EXIT_CODE=$?
          echo "Launch exit code: $LAUNCH_EXIT_CODE"
          echo "Launch output:"
          echo "$LAUNCH_OUTPUT"

          if [ $LAUNCH_EXIT_CODE -ne 0 ]; then
            echo "❌ AgentCore launch failed with exit code $LAUNCH_EXIT_CODE"
            echo "Full launch output:"
            echo "$LAUNCH_OUTPUT"
            echo ""
            echo "🔍 Debugging information:"
            echo "- Current directory: $(pwd)"
            echo "- Files in directory:"
            ls -la
            echo "- AWS identity:"
            aws sts get-caller-identity 2>/dev/null || echo "AWS CLI not available"
            echo "- AgentCore config exists:"
            [ -f ".bedrock_agentcore.yaml" ] && echo "✅ Config file found" || echo "❌ Config file missing"
            exit $LAUNCH_EXIT_CODE
          fi

          # Extract runtime ARN from launch output - look for various ARN patterns
          RUNTIME_ARN=$(echo "$LAUNCH_OUTPUT" | grep -o 'arn:aws:bedrock:[^[:space:]]*' | head -1)

          # If not found in launch output, try status command
          if [ -z "$RUNTIME_ARN" ]; then
            echo "ARN not found in launch output, checking status..."
            RUNTIME_ARN=$(agentcore status | grep -o 'arn:aws:bedrock:[^[:space:]]*' | head -1)
          fi

          # If still not found, try to get it from AWS CLI
          if [ -z "$RUNTIME_ARN" ]; then
            echo "ARN not found, trying AWS CLI..."
            AGENT_NAME="secureauditai_agent_${ENVIRONMENT}"
            RUNTIME_ARN=$(aws bedrock-agent list-agents --region ${{ env.AWS_REGION }} | jq -r ".agentSummaries[] | select(.agentName==\"$AGENT_NAME\") | .agentArn" 2>/dev/null | head -1)
          fi

          if [ -z "$RUNTIME_ARN" ]; then
            echo "❌ Could not find runtime ARN. Please check the agentcore launch output above."
            exit 1
          fi

          echo "runtime_arn=${RUNTIME_ARN}" >> $GITHUB_OUTPUT
          echo "✅ AgentCore Runtime deployed: ${RUNTIME_ARN}"
          echo "📝 With Memory: ${{ steps.setup-agentcore-resources.outputs.memory_id }}"
          echo "🌐 With Gateway: ${{ steps.setup-agentcore-resources.outputs.gateway_id }}"

      - name: Store AgentCore Runtime ARN in SSM
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          STACK_NAME="secureauditai-agent-${ENVIRONMENT}"
          RUNTIME_ARN="${{ steps.deploy-agentcore.outputs.runtime_arn }}"

          # Store runtime ARN for Lambda functions to use
          aws ssm put-parameter \
            --name "/${STACK_NAME}/${ENVIRONMENT}/agentcore_runtime_arn" \
            --value "${RUNTIME_ARN}" \
            --type String \
            --overwrite \
            --region ${{ env.AWS_REGION }}

      - name: Check AgentCore deployment status
        if: github.event.inputs.environment == 'prod'
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          aws ecr describe-repositories --repository-names "secureauditai-agentcore-${ENVIRONMENT}" --region ${{ env.AWS_REGION }} >/dev/null 2>&1 && aws ecr describe-images --repository-name "secureauditai-agentcore-${ENVIRONMENT}" --region ${{ env.AWS_REGION }} --query 'imageDetails[0].imageDigest' >/dev/null 2>&1

      - name: Verify deployment health
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          STACK_NAME="secureauditai-agent-${ENVIRONMENT}"

          # Check CloudFormation stack status
          STACK_STATUS=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].StackStatus' --output text --region ${{ env.AWS_REGION }})

          if [[ "$STACK_STATUS" != *"COMPLETE"* ]]; then
            echo "CloudFormation stack in failed state: $STACK_STATUS"
            exit 1
          fi

          # Check Amplify app status
          AMPLIFY_APP_ID="${{ steps.cf-outputs.outputs.AMPLIFY_APP_ID }}"
          aws amplify get-branch --app-id "$AMPLIFY_APP_ID" --branch-name "$ENVIRONMENT" --query 'branch.branchArn' --output text --region ${{ env.AWS_REGION }} >/dev/null

      - name: Cleanup on failure
        if: failure()
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          STACK_NAME="secureauditai-agent-${ENVIRONMENT}"

          # Check if stack exists and is in a failed state
          if aws cloudformation describe-stacks --stack-name "$STACK_NAME" --region ${{ env.AWS_REGION }} &> /dev/null; then
            STACK_STATUS=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --query 'Stacks[0].StackStatus' --output text --region ${{ env.AWS_REGION }})

            if [[ "$STACK_STATUS" == *"FAILED"* ]] || [[ "$STACK_STATUS" == *"ROLLBACK"* ]]; then
              aws cloudformation delete-stack --stack-name "$STACK_NAME" --region ${{ env.AWS_REGION }}
              aws cloudformation wait stack-delete-complete --stack-name "$STACK_NAME" --region ${{ env.AWS_REGION }} || true
            fi
          fi

          # Clean up any temporary files
          rm -f frontend/amplify-deployment.zip packaged-template.yaml .cf-validation || true

  # Post-deployment validation
  validate-deployment:
    name: Validate Deployment
    runs-on: ubuntu-latest
    needs: deploy
    if: always() && needs.deploy.result == 'success'
    timeout-minutes: 5
    steps:
      - name: Validate deployment
        run: |
          echo "Deployment validated for ${{ github.event.inputs.environment }}"

  # Cleanup resources (manual trigger)
  cleanup:
    name: Cleanup Resources
    runs-on: ubuntu-latest
    if: github.event.inputs.environment == 'cleanup'
    timeout-minutes: 30
    steps:
      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/personal-github-oidc-role
          aws-region: ${{ env.AWS_REGION }}

      - name: Cleanup CloudFormation stacks
        run: |
          echo "Starting cleanup of SecureAuditAI resources..."

          # List of environments to clean up
          ENVIRONMENTS=("dev" "test" "prod")

          for ENV in "${ENVIRONMENTS[@]}"; do
            STACK_NAME="secureauditai-agent-${ENV}"

            echo "Checking stack: $STACK_NAME"

            if aws cloudformation describe-stacks --stack-name "$STACK_NAME" --region ${{ env.AWS_REGION }} &> /dev/null; then
              echo "Found stack: $STACK_NAME"

              # Disable termination protection first
              echo "Disabling termination protection for $STACK_NAME..."
              aws cloudformation update-termination-protection \
                --stack-name "$STACK_NAME" \
                --no-enable-termination-protection \
                --region ${{ env.AWS_REGION }} || echo "Failed to disable termination protection, continuing..."

              # Delete the stack
              echo "Deleting stack: $STACK_NAME..."
              aws cloudformation delete-stack \
                --stack-name "$STACK_NAME" \
                --region ${{ env.AWS_REGION }}

              # Wait for deletion to complete
              echo "Waiting for stack deletion to complete..."
              aws cloudformation wait stack-delete-complete \
                --stack-name "$STACK_NAME" \
                --region ${{ env.AWS_REGION }} || echo "Stack deletion may still be in progress"

              echo "Stack $STACK_NAME deletion initiated"
            else
              echo "Stack $STACK_NAME does not exist"
            fi
          done

          # Also clean up deployment buckets
          echo "Cleaning up deployment buckets..."
          for ENV in "${ENVIRONMENTS[@]}"; do
            BUCKET_NAME="secureauditai-deployment-us-west-2-${ENV}"

            if aws s3 ls s3://${BUCKET_NAME} --region ${{ env.AWS_REGION }} &> /dev/null; then
              echo "Deleting deployment bucket: $BUCKET_NAME"
              aws s3 rb s3://${BUCKET_NAME} --force --region ${{ env.AWS_REGION }} || echo "Failed to delete bucket $BUCKET_NAME"
            else
              echo "Bucket $BUCKET_NAME does not exist"
            fi
          done

          echo "Cleanup completed"